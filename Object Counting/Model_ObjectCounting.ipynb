{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Data_Constructor.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a151bd",
   "metadata": {
    "id": "K4K-nnVMdJ5B"
   },
   "source": [
    "## 1.&nbsp;Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea1efb",
   "metadata": {
    "id": "byNo_hpzXlYS"
   },
   "source": [
    "**define model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0bd00b",
   "metadata": {
    "id": "CgBgfdjtqr5k"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A double convolution module used to extract features.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels. For example for an\n",
    "            input of shape (batch_size, 3, img_size, img_size) in_channels\n",
    "            is 3.\n",
    "        out_channels (int): number of output_channels desired. For example\n",
    "            if the desired output shape is (batch_size, 3, img_size, img_size)\n",
    "            in_channels is 3.\n",
    "        kernel_size (int): A kernel of shape (kernel_size, kernel_size)\n",
    "            will be applied to the imgs during both Conv2d layers.\n",
    "        bias (bool): whether or not to add a bias to the Conv2d layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, bias=True):\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride=1,\n",
    "                padding=\"same\",\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride=1,\n",
    "                padding=\"same\",\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ObjectCounter(nn.Module):\n",
    "    \"\"\"An object counting model that uses multiple conv layers and then\n",
    "    two fully connected layers to determine how many instances of different\n",
    "    classes of objects (shapes) are in an image.\n",
    "\n",
    "    Args:\n",
    "        img_size (int): model will take images of shape\n",
    "            (3, img_size, img_size).\n",
    "        in_channels (int): number of input channels. For example for an\n",
    "            put of shape (batch_size, 3, img_size, img_size) in_channels\n",
    "            is 3.\n",
    "        num_classes (int): number of output classes desired. The output\n",
    "            shape of the model will be (batch_size, num_classes).\n",
    "        features (List[int]): A list specifying the number of features to\n",
    "            be used in each DoubleConv layer. Note that for the model to\n",
    "            work the image_size must be divisable by {(2** len(features))}.\n",
    "        kernel_size (int): A kernel of shape (kernel_size, kernel_size)\n",
    "            will be applied to the imgs during both Conv2d layers.\n",
    "        fc_intermediate_size (int): Size of the output of the first\n",
    "            fully connected layer (fc1) and size of the input of the second\n",
    "            fully connected layer (fc2).\n",
    "        bias (bool): whether or not to add a bias to the Conv2d layers.\n",
    "        track_x_shape (bool): whether or not to track the shape of x.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size=256,\n",
    "        in_channels=3,\n",
    "        num_classes=3,\n",
    "        features=[16, 32],\n",
    "        kernel_size=3,\n",
    "        fc_intermediate_size=10,\n",
    "        bias=True,\n",
    "        track_x_shape=False,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.features = features\n",
    "        self.kernel_size = kernel_size\n",
    "        self.fc_intermediate_size = fc_intermediate_size\n",
    "        self.bias = True\n",
    "        self.track_x_shape = track_x_shape\n",
    "\n",
    "        final_size = self.img_size / (2 ** len(self.features))\n",
    "\n",
    "        if (final_size % 1) != 0:\n",
    "            raise ValueError(f\"image_size must be divisable by {(2** len(features))}.\")\n",
    "\n",
    "        self.final_size = int(final_size)\n",
    "        self.final_feature_size = self.features[-1]\n",
    "        self.fc_in_size = self.final_feature_size * self.final_size**2\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(self.fc_in_size, self.fc_intermediate_size)\n",
    "        self.fc2 = nn.Linear(self.fc_intermediate_size, self.num_classes)\n",
    "        self.feature_extractor = nn.ModuleList()\n",
    "\n",
    "        if self.track_x_shape:\n",
    "            self.x_shape_tracker = []\n",
    "\n",
    "        # Feature extractor\n",
    "        for feature in features:\n",
    "            self.feature_extractor.append(\n",
    "                DoubleConv(\n",
    "                    in_channels, feature, kernel_size=self.kernel_size, bias=self.bias\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.track_shape( x, \"input shape\")\n",
    "        for i, module in enumerate(self.feature_extractor):\n",
    "\n",
    "            x = module(x)\n",
    "            self.track_shape( x, f\"feature_extractor layer {i}\")\n",
    "            x = self.pool(x)\n",
    "            self.track_shape( x, f\"max pool layer {i}\")\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.track_shape( x, \"reshape\")\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        self.track_shape( x, \"fc1\")\n",
    "\n",
    "        x = self.relu(x)\n",
    "        self.track_shape( x, \"relu\")\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        self.track_shape( x, \"fc2 (output shape)\")\n",
    "\n",
    "        return x\n",
    "\n",
    "    def track_shape(self, x, description):\n",
    "        if self.track_x_shape:\n",
    "            self.x_shape_tracker.append((f\"{description}:\\n\\t {x.shape}\"))\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85814153",
   "metadata": {
    "id": "2xUomQhMXCR3"
   },
   "source": [
    "**sanity check model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee38114",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDWZubRW9cxF",
    "outputId": "423df124-536a-418a-aee9-5ad045962139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([13, 3, 256, 256]) \n",
      "Output shape: torch.Size([13, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "img_size = 256\n",
    "batch_size = 13\n",
    "\n",
    "x = torch.rand((batch_size, 3, img_size,img_size))\n",
    "\n",
    "model = DoubleConv(3, 4, kernel_size = 11)\n",
    "logits = model(x)\n",
    "print(f\"Input shape: {x.shape} \" )\n",
    "print(f\"Output shape: {logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ed394e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18avWxov2oFd",
    "outputId": "148e300d-2d12-4d29-e6c8-d3141194ba0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.x_shape_tracker: \n",
      "\n",
      "input shape:\n",
      "\t torch.Size([13, 3, 256, 256]) \n",
      "\n",
      "feature_extractor layer 0:\n",
      "\t torch.Size([13, 7, 256, 256]) \n",
      "\n",
      "max pool layer 0:\n",
      "\t torch.Size([13, 7, 128, 128]) \n",
      "\n",
      "feature_extractor layer 1:\n",
      "\t torch.Size([13, 11, 128, 128]) \n",
      "\n",
      "max pool layer 1:\n",
      "\t torch.Size([13, 11, 64, 64]) \n",
      "\n",
      "feature_extractor layer 2:\n",
      "\t torch.Size([13, 15, 64, 64]) \n",
      "\n",
      "max pool layer 2:\n",
      "\t torch.Size([13, 15, 32, 32]) \n",
      "\n",
      "reshape:\n",
      "\t torch.Size([13, 15360]) \n",
      "\n",
      "fc1:\n",
      "\t torch.Size([13, 10]) \n",
      "\n",
      "relu:\n",
      "\t torch.Size([13, 10]) \n",
      "\n",
      "fc2 (output shape):\n",
      "\t torch.Size([13, 2]) \n",
      "\n",
      "Example output: tensor([-0.2813, -0.0374], grad_fn=<SelectBackward0>)\n",
      "\n",
      "model.final_size: 32\n",
      "model.final_feature_size: 15\n",
      "model.fc_in_size: 15360\n",
      "\n",
      "Conv2d(3, 7, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
      "torch.Size([7, 3, 7, 7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "model = ObjectCounter(img_size = img_size, in_channels = 3, num_classes = 2, features=[7,11,15], kernel_size = 7, track_x_shape = True )\n",
    "logits = model(x)\n",
    "\n",
    "print(\"model.x_shape_tracker: \\n\")\n",
    "for shape in model.x_shape_tracker:\n",
    "    print(shape, \"\\n\")\n",
    "\n",
    "print(f\"Example output: {logits[0]}\\n\")\n",
    "\n",
    "print(f\"model.final_size: {model.final_size}\")\n",
    "print(f\"model.final_feature_size: {model.final_feature_size}\")\n",
    "print(f\"model.fc_in_size: {model.fc_in_size}\\n\")\n",
    "\n",
    "print(model.feature_extractor[0].conv[0])\n",
    "print(model.feature_extractor[0].conv[0].weight.shape)\n",
    "print(model.feature_extractor[0].conv[0].bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca5fa4",
   "metadata": {
    "id": "5xBV8mSKdFBg"
   },
   "source": [
    "## 2.&nbsp;Overfit a Small Batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933d1bc",
   "metadata": {
    "id": "mlhYUdWQweLW"
   },
   "source": [
    "**overfit function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1bca72",
   "metadata": {
    "id": "U3a6BMX3dgCx"
   },
   "outputs": [],
   "source": [
    "def overfit(imgs, labels, model, optimizer,  device,  epochs= 100):\n",
    "\n",
    "    loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Formatting for input to model.\n",
    "    imgs_normed = imgs.float() / 255.0\n",
    "    imgs_normed = imgs_normed.to(device)\n",
    "    labels = labels.float().to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        logits = model(imgs_normed).to(device)\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch %25 == 0:\n",
    "            print(f\"epoch: {epoch}\")\n",
    "            print(f\"loss: {loss:.6f}\\n\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1dd41f",
   "metadata": {
    "id": "OvscHdXlw3va"
   },
   "source": [
    "**small batch to overfit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "235ad88e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HT9s5Sj1etEK",
    "outputId": "a520b0da-363d-467d-b92c-5ecdc887b636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up fit stage.\n"
     ]
    }
   ],
   "source": [
    "obj_counting_dm = ObjectCounting_DM(\n",
    "                                train_val_size = 10,\n",
    "                                img_size = 256,\n",
    "                                batch_size=4,\n",
    "                                train_val_split = (.8,.2),\n",
    "                                shapes_per_image = (0,4),\n",
    "                                class_probs=(1,1,1),\n",
    "                                rand_seed= 123456,\n",
    "                                object_count = True,\n",
    "                                class_map={\n",
    "                                    0: {\"name\": \"background\", \"gs_range\": (200, 255), \"target_color\": (255,255,255)},\n",
    "                                    1: {\"name\": \"rectangle\", \"gs_range\": (0, 100), \"target_color\": (255, 0, 0)},\n",
    "                                    2: {\"name\": \"line\", \"gs_range\": (0, 100), \"target_color\": (0, 255, 0)},\n",
    "                                    3: {\"name\": \"donut\", \"gs_range\": (0, 100), \"target_color\": (0, 0, 255)},\n",
    "                                },\n",
    "                                dataloader_shuffle={\"train\": False, \"val\": False, \"test\": False},\n",
    "                                    )\n",
    "\n",
    "# Visualize and understand some random images\n",
    "obj_counting_dm.setup(stage = \"fit\")\n",
    "dataiter = iter(obj_counting_dm.train_dataloader())\n",
    "\n",
    "imgs, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c2244",
   "metadata": {
    "id": "r61gxzcYZ5cg"
   },
   "source": [
    "**run overfit function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bcbb68f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ocg6C99eXCn",
    "outputId": "8bec21e5-bd1c-4828-b945-8f3b5af1b046",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "loss: 0.847755\n",
      "\n",
      "epoch: 25\n",
      "loss: 0.559450\n",
      "\n",
      "epoch: 50\n",
      "loss: 0.390993\n",
      "\n",
      "epoch: 75\n",
      "loss: 0.285023\n",
      "\n",
      "epoch: 100\n",
      "loss: 0.219508\n",
      "\n",
      "epoch: 125\n",
      "loss: 0.176054\n",
      "\n",
      "epoch: 150\n",
      "loss: 0.144657\n",
      "\n",
      "epoch: 175\n",
      "loss: 0.120050\n",
      "\n",
      "epoch: 200\n",
      "loss: 0.100053\n",
      "\n",
      "epoch: 225\n",
      "loss: 0.083733\n",
      "\n",
      "epoch: 250\n",
      "loss: 0.070526\n",
      "\n",
      "epoch: 275\n",
      "loss: 0.059936\n",
      "\n",
      "epoch: 300\n",
      "loss: 0.051575\n",
      "\n",
      "epoch: 325\n",
      "loss: 0.045040\n",
      "\n",
      "epoch: 350\n",
      "loss: 0.039987\n",
      "\n",
      "epoch: 375\n",
      "loss: 0.036107\n",
      "\n",
      "epoch: 400\n",
      "loss: 0.033141\n",
      "\n",
      "epoch: 425\n",
      "loss: 0.030858\n",
      "\n",
      "epoch: 450\n",
      "loss: 0.029378\n",
      "\n",
      "epoch: 475\n",
      "loss: 0.028485\n",
      "\n",
      "epoch: 500\n",
      "loss: 0.027824\n",
      "\n",
      "epoch: 525\n",
      "loss: 0.027244\n",
      "\n",
      "epoch: 550\n",
      "loss: 0.026691\n",
      "\n",
      "epoch: 575\n",
      "loss: 0.026151\n",
      "\n",
      "epoch: 600\n",
      "loss: 0.025618\n",
      "\n",
      "epoch: 625\n",
      "loss: 0.025090\n",
      "\n",
      "epoch: 650\n",
      "loss: 0.024567\n",
      "\n",
      "epoch: 675\n",
      "loss: 0.024049\n",
      "\n",
      "epoch: 700\n",
      "loss: 0.023535\n",
      "\n",
      "epoch: 725\n",
      "loss: 0.023026\n",
      "\n",
      "epoch: 750\n",
      "loss: 0.022521\n",
      "\n",
      "epoch: 775\n",
      "loss: 0.022023\n",
      "\n",
      "epoch: 800\n",
      "loss: 0.021529\n",
      "\n",
      "epoch: 825\n",
      "loss: 0.021042\n",
      "\n",
      "epoch: 850\n",
      "loss: 0.020560\n",
      "\n",
      "epoch: 875\n",
      "loss: 0.020085\n",
      "\n",
      "epoch: 900\n",
      "loss: 0.019615\n",
      "\n",
      "epoch: 925\n",
      "loss: 0.019152\n",
      "\n",
      "epoch: 950\n",
      "loss: 0.018696\n",
      "\n",
      "epoch: 975\n",
      "loss: 0.018246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ObjectCounter(img_size = imgs.shape[-1], in_channels = 3, num_classes = 3, features=[4,8], fc_intermediate_size = 10, bias = True )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-6)\n",
    "overfit(imgs, labels, model, optimizer,  device, epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c448007",
   "metadata": {
    "id": "KKYry43b1V8K"
   },
   "source": [
    "**get predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656fe3e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j21ole35qR28",
    "outputId": "67d0ee2d-6a54-40bf-daca-29991ccf5d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logits:\n",
      " tensor([[-0.0582,  0.1710,  0.2199],\n",
      "        [ 0.8337,  1.0292,  1.1120],\n",
      "        [ 1.2014,  0.9485,  1.8048],\n",
      "        [-0.0730,  1.0167,  0.0680]], device='cuda:0')\n",
      "\n",
      "preds:\n",
      " tensor([[0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [0, 1, 0]], device='cuda:0')\n",
      "\n",
      "labels:\n",
      " tensor([[0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Formatting for input to model.\n",
    "imgs_normed = imgs.float() / 255.0\n",
    "imgs_normed = imgs_normed.to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(imgs_normed)\n",
    "\n",
    "preds = logits.round().long().to(device)\n",
    "print(f\"\\nlogits:\\n {logits}\")\n",
    "print(f\"\\npreds:\\n {preds}\")\n",
    "print(f\"\\nlabels:\\n {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f0dd4",
   "metadata": {
    "id": "U0MpDdDDCceA"
   },
   "source": [
    "**visualize overfit predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1734f313",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334,
     "referenced_widgets": [
      "175ffd0117da409990559dafd2f640ce",
      "071b8586667741fd9150d5267d9db2f6",
      "ff33449133904a8495ab91d70d87979a",
      "efa966e4296b46d8a4aae7dc988d808e",
      "45d175149f9246f3bc7cb259bb964c21",
      "74b3db393eca411a99adb2e475f8d074",
      "50a30080f0da47e8a7ff1252f818b44b",
      "84cb19736004455f98ed5f8f5b5a0263",
      "03ec79598f1c4f2b8c5da1b48b1e1af9",
      "83cc82e468834ea8afed92c266c93fbe",
      "8ffc37e0db4047c98bd74042a5af3c7d",
      "d23a2c3c91b44610b9fb48e8d32e5ff8",
      "7cbc2188dae949ba93704d47d5f373a7"
     ]
    },
    "id": "FN9c9fEqDGG4",
    "outputId": "8e620018-8b30-4de7-cb86-1c544b0cfd9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f3625f120e4fd9984a54463f75beab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='display_labels'), Checkbox(value=False, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "@interact\n",
    "def vizualize_targets_predictions(\n",
    "                                 show_labels = widgets.Checkbox(value=False,description='display_labels'),\n",
    "                                 show_preds = widgets.Checkbox(value=False,description='display_preds'),\n",
    "                                 display_size = widgets.IntSlider(value=30,min=2,max=50,step=1),\n",
    "                                ):\n",
    "\n",
    "    result_images = [imgs[i] for i in range(len(imgs))]\n",
    "\n",
    "    if  show_labels:\n",
    "        result_images = [add_labels(img, label, obj_counting_dm.class_map, object_count = True) for img, label in zip(result_images, labels)]\n",
    "    if  show_preds:\n",
    "        result_images = [add_labels(img, pred, obj_counting_dm.class_map, object_count = True, pred = True) for img, pred in zip(result_images, preds)]\n",
    "\n",
    "    grid = make_grid(result_images)\n",
    "    show(grid, figsize = (display_size,display_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baba7e6",
   "metadata": {
    "id": "xyF2o1bVCkhG"
   },
   "source": [
    "## 3.&nbsp;Build Lightning Module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "469c675b",
   "metadata": {
    "id": "9nAaBZWECkhG"
   },
   "outputs": [],
   "source": [
    "class LightningObjCounter(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, in_channels=3, num_classes=3, img_size = 256, features = [4,8], kernel_size = 3, fc_intermediate_size = 10, bias = True, lr = 5e-6):\n",
    "        super().__init__()\n",
    "\n",
    "        # LM attributes.\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.img_size = img_size\n",
    "        self.features = features\n",
    "        self.kernel_size = kernel_size\n",
    "        self.fc_intermediate_size = fc_intermediate_size\n",
    "        self.bias = True\n",
    "        self.lr = lr\n",
    "\n",
    "        # Log hyperparameters.\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Metrics.\n",
    "        self.train_acc = torchmetrics.Accuracy(num_classes=4,task=\"multiclass\", multidim_average = 'samplewise')\n",
    "        self.train_f1 = torchmetrics.F1Score(num_classes=4,task=\"multiclass\", multidim_average = 'samplewise')\n",
    "        self.val_acc = torchmetrics.Accuracy(num_classes=4,task=\"multiclass\", multidim_average = 'samplewise')\n",
    "        self.val_f1 = torchmetrics.F1Score(num_classes=4,task=\"multiclass\", multidim_average = 'samplewise')\n",
    "\n",
    "        # Loss function.\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        # Model.\n",
    "        self.model = ObjectCounter(img_size = self.img_size,\n",
    "                                    in_channels = self.in_channels,\n",
    "                                    num_classes = self.num_classes,\n",
    "                                    features = self.features,\n",
    "                                    kernel_size = self.kernel_size,\n",
    "                                    fc_intermediate_size = self.fc_intermediate_size,\n",
    "                                    bias = self.bias )\n",
    "\n",
    "        # Sample input. Used for logging the model graph.\n",
    "        self.example_input_array = torch.rand(16,3,self.img_size, self.img_size)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "\n",
    "        imgs_normed = imgs.float() / 255.0\n",
    "        return self.model(imgs_normed)\n",
    "\n",
    "  # Utility function.\n",
    "    def custom_histogram_adder(self):\n",
    "        # iterating through all parameters\n",
    "        for name,params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name,params,self.current_epoch)\n",
    "\n",
    "    def mse_loss(self, logits, labels):\n",
    "        labels = labels.float()\n",
    "        return self.loss(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "\n",
    "        # Grab images and labels from batch.\n",
    "        imgs, labels = train_batch\n",
    "\n",
    "        logits = self.forward(imgs)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = self.mse_loss(logits, labels)\n",
    "\n",
    "        preds = logits.clamp(min = 0).round().long()\n",
    "        # Log step metrics.\n",
    "        self.train_acc(preds, labels)\n",
    "        self.train_f1(preds, labels)\n",
    "\n",
    "        self.log('Loss/train_loss', loss)\n",
    "#         self.log('Acc/train_acc', self.train_acc, on_step = True)\n",
    "#         self.log('F1/train_f1', self.train_f1, on_step = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "        # Log histograms.\n",
    "        if batch_idx ==0:\n",
    "            self.custom_histogram_adder()\n",
    "\n",
    "        # Grab images and labels from batch.\n",
    "        imgs, labels = val_batch\n",
    "        # labels = F.one_hot(labels, num_classes = self.max_class_occurance+1)\n",
    "\n",
    "        logits = self.forward(imgs)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = self.mse_loss(logits, labels)\n",
    "\n",
    "        preds = logits.clamp(min = 0).round().long()\n",
    "        # Log step metrics.\n",
    "        self.val_acc(preds, labels)\n",
    "        self.val_f1(preds, labels)\n",
    "\n",
    "\n",
    "        self.log('Loss/val_loss', loss)\n",
    "#         self.log('Acc/val_acc', self.val_acc, on_step = True)\n",
    "#         self.log('F1/val_f1', self.val_f1, on_step = True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Remember to make the optim input self.model.parameters()!\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb1b58",
   "metadata": {
    "id": "19jXEs3MCkhG"
   },
   "source": [
    "## 4.&nbsp; Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8ef4c",
   "metadata": {
    "id": "hts2EfuZMJYZ"
   },
   "source": [
    "**define trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "122d60a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468,
     "referenced_widgets": [
      "ffc268e421a04e81ac9cf05bfc9a8e25",
      "b154ebec96c743d8aea5b53af58533b4",
      "80a5859ce2bf42f5ab5a1caf7d16a32f",
      "8bf3aa8bddf944959a8c26b02b10823d",
      "2ce8fffbc3194d508b4b7e31eac099b6",
      "730694d245014c3596947401d85bc5fc",
      "61bd9a4110ca4c3f82f595f6509c71d7",
      "39b8d5c080aa4dd99772118719b0388e",
      "26e5878218cb414fa5a28858a2024923",
      "7c5fba04cb0c4e69815557b505133b53",
      "0ba26e6321b34e2b97bbe5e96b2ecfe6",
      "eb48b317f0ee40639553e50490a44ad3",
      "853bbff721294c378f632338d9b7ec2a",
      "2f58ba6761954653abc3aaf815155a6d",
      "ac90bccc80084e06815e2d56f2ea4246",
      "0b2192b2cdb445f885a0417b25451daf",
      "42f2f4820e8c488eb79fe59103a65e9a",
      "59f632ef9a314866a8cb3c934afa8d87",
      "be1cee47ca4846ecbda32f95ad2a07f6",
      "188604cb3d104f5a879a37bc6d4ae389",
      "a7034832bb8848118df8a80284d952df",
      "dffc39afbb3a4d89971f698cbfcc28be",
      "fab2b53db5a1470985649c07d07de3cf",
      "8ad6c0d8bd0d42efaa20233f45aa3f7b",
      "d22300826f5540caabde6a2d845b09df",
      "72e38e2396324c8ebc958bfdf787fde8",
      "37bbf829665f45e8b8a5e0914b7800f2",
      "e827c189e8eb44269c6d2d712cdc1c09",
      "e003263d1ebd42e48bfa5729e05f2439",
      "dde6a9a1928d4f8bb5a9a20de81c933e",
      "56e4e647feae4cc2bb32d01ddfb0f864",
      "e9d7f2e4bd614804b4de619763bd5d80",
      "3414a02c2f0948ee8802fce5a3d6d842",
      "3675a360e86f46f39c0c8b81dcfc0815",
      "07871eb83e6d415a8e54bac897563bfb",
      "ffb5420122f547ae94cd0d8d3cbd2bcc",
      "239429c9719146cf93525342853a4d0f",
      "6b48302cf0084506adb6b34e6ee35a6b",
      "e73ae9b7faab4d83875e3522766daa6c",
      "3b683cffdb7546db9024bb443b12ce5b",
      "355f37fffccc4ef2aa41a44bf86ade85",
      "8193acdbab1a4acf8df9a13b35dfaef5",
      "8658eb406ba747efb5bf473a1716cf58",
      "e5e4bc0acc704381bbba6f001563ffcf",
      "70991cc9569945df80e7a78669dc59c8",
      "0fe7d46b7dcf4d459c6ea52f894799a2",
      "8563c7b178424a999de7ffd828954183",
      "71ac5e6a4b54493884ef69ea36d642c3",
      "25219c85a6744c1db7f5c21ffe0269e3",
      "f542ebfbda54454cab17cde3826643bf",
      "6647d2e8e58f453f81e554b86e110a7d",
      "e505c72998554d989499f8d07e09d039",
      "c88256b764214f50a8c409805870c556",
      "860d3f1e0c634677b898b7dca5c3ab7e",
      "dcc7d66172684219bd3e721a71aac5bf",
      "d00eb8dc7bc24b10b5920928c856755f",
      "6dccbcb717bf4e64a5636190d5797788",
      "88e7d11cf06a481ebab53949f4cbb37e",
      "9b3c764d20ad4abb993cbfed88abf409",
      "39df6f6c54154eee9d8eddefa699a4db",
      "be70ab8e4c5e49439ee3a791cae054e9",
      "eb9101e58b634d16bf92de2a86197050",
      "560a05e0193a48cfbda32b737bd30ba5",
      "2557f9f906c4452e97efdda8762658f7",
      "407f94e4c1d14c3e997542c5e2a04df0",
      "361578521c564f9e8dc41041cc2b480f",
      "f48e9904fd0b4f4083f5f75b0ca8a2d9",
      "6e00c24845d94c318fd629bb32904dd3",
      "daf54694b8d640dd857c081823ab8b92",
      "90f2237eb39546efbc0a2fe6dadc2ba4",
      "5e27b98ab4944b869c299390209e9419",
      "6d116bd3387c478ea3461d33de919ef4",
      "cd3decf38f6841a0b390760285297b16",
      "8f8d3d3819e648fd89717239e0e33063",
      "29e3912436de4a298be3d1dc301d6aa5",
      "f4e02247098d457ea78a6c21fa65359c",
      "815e5cfb37eb4b84980b131ecdcc4b8b",
      "4121be34316d4afd9d814e417e60a7fc",
      "8dc5b2f803264f80a8992433e7af56c2",
      "34500a8dac7b41fb9400d9065e0fd975",
      "0a966a4ef7864304ae3cf1ed92bb9878",
      "2e3351b6085b425bb7bc4bbde069027d",
      "f801123f69ac4a37a58ff05a46a08970",
      "157d12adec5648ba9ddbd3689a4b0888",
      "62421be1498c4cfc8131f7176ec41e8a",
      "641bae10084849a19f5ac3d00d1ead66",
      "22804634f4374ed6a19a7758b80436ac",
      "134f7a9643b04275bb3eb74b2e3360b6",
      "7e6b0be5f9694597ab2fa7eb37a13205",
      "dede2900f1c64562910f731ad194ae60",
      "a09d116897b5497498069ad71ad6a643",
      "c448271d339a4f10843afe29f91ea81e",
      "e096abede9e749ad8386142ce921de45",
      "9ea22cd24c1345508bf91874411513d4",
      "3504622e2a684903a7bf5d20a2e196bb",
      "9eb80a757fcc45308387ff792675d7c5",
      "ef3a1665be2b4810be56f0ad3423644c",
      "6273bc5dd6de4c6f8d5e81d28ea092d8",
      "1d8d6d6f2eb4453bb8d7091008e2ef22",
      "b9affc2c933e43ecaad8081e2fc92e94",
      "d2a1fd4ad4834b5a850879a08ce189e3",
      "970e1733c70f4158997917f9a13833d8",
      "934340fc22184239af66e467ee5fba07",
      "4b654412bf874fc6864248d21bb6032f",
      "c7cd396f343f467e9e9430af77844d7f",
      "a48223c7f7f349648640726cfb4ddd9a",
      "27117597b8844d378ba7282e5dc7cf88",
      "56c8f6bb30ab4771b841f6675bf35c96",
      "ad9f6aa4b108419d997bed086b8eb0da",
      "505e9e7531894a3aa721fb64244d233b",
      "89f031a492034ea0be66c1c610b50954",
      "03145cedaa894b9e95bc8ee7248c3e6c",
      "624f99a69e4742faa0abd4cb23367963",
      "b894de7520a44b03be6085a89ff289f1",
      "193407d5b32e419fb3b252bfa6b7bb81",
      "aadf714d498f439c9296b0c6f6e75cb6",
      "79a4126473734b02b44112a3b64cb582",
      "d8d27e9bdb87405fa7c86a61254ace43",
      "490f5411070d40008e9a6cdd5382eacb",
      "d669a32a48a341829f523eaae0b8571a",
      "732aab64d20c42339e98bf36f074e910",
      "c97f823b32b74997a07ac13f19e60678",
      "403b7142c2b546a685f45cbfdec27e9e",
      "bed07e0e2c0f4da1b86009a6e53dc011",
      "3fb7c568b9334edb935d4dedf0615117",
      "f7f3c52cf8cb4679aa8d9170ebc33f06",
      "91609f1c995e450bbe4697ecd6f1826e",
      "3825ab18b40547999d33b1d8ce11809f",
      "6f3396fc0f7a4479b529036207f2cf4e",
      "d7ed166e2ee3454e905dd066ed508e75",
      "6ff07f5d8de74bdea5631f2fbef35b43",
      "346e59344087469da76bbed0e5aefe5f",
      "dbb0e6873b244c4c940aaedbbf0a0c34",
      "539a327302794979b55c4f25dcd8f3cf",
      "cd5748da61d846b58bc15243e71210e9",
      "72af39b339dd41f6af8021feccfd0748",
      "b9b631faf5044ad6912357ba22973f62",
      "54eba0f42f5e400da9f835fa13592c77",
      "2f54ba4755494fb084badf8b76188d52",
      "77861a78dfd94e4480b95215f0766047",
      "0df9cc3a15b2489496519a3482517780",
      "7ebdbb9429b540f896aa2e72e3491c58",
      "fe48dd6e0d8c4c169e77be4a1fcbe818",
      "ed58d9e795914d7cb3ce858a9aee71a3",
      "1e4b1d2e5e4848c2a2b7b1dd42e5a746",
      "8c27c7f726df4a7391ce581107a544b2",
      "0eb8028cb1b244e3acf5cadfa97c572b",
      "1bad7fc86fd840499a92c46c19684fac",
      "5e31511bd759465a9699c636453f1378",
      "cb6d5ad750f24b3d85631e6d9768f2db",
      "7f59a5d8f2be4053b797d0491d80fb93",
      "56fd26e2f8074b76b6537da58b03a60a",
      "a64f9e2843704a12b2276c39c09e197f",
      "e6d7996554e749809186c19578b2d925",
      "cf49b5f27980475cbfd024e3eb456b15",
      "dd262301118c408b961da5887310afe7",
      "2bd1c3a3289d4763a45580cf4761586a",
      "37d1642b7cee49f287e6d77f0fb979c7",
      "5f21fbd32dcb4cbfbe23bd5e36877a0c",
      "ec97b4d0503c499c9be3b52a15902118",
      "457ea9936a6c40b7a12424c344b1b8d6",
      "e710d10f39184194ad63c089fe84224d",
      "6ae27e3167844ed7987422e47663a99d",
      "fef6e4c1e80a45b19aa546969e08e214",
      "724ed97a113742e489bc1ea52c3e37f8",
      "f641d257426d40498f34f7568d8e1ee2",
      "91bb7f257e0b4e0ca781ae8c4dbe9290",
      "7dc0ad7c6f2c418fb4cc558e3b220d25",
      "4fdc532f45954bc68d067bdc0fd75e68",
      "bdf23dcd2f1c4dd19f05251de3938a6d",
      "4d0e2b734b8844c4a5602c84df904b3b",
      "b004674c4ec44361a914e4ada682820d",
      "02f55696cf004fbe86e4b0fe3da9a82f",
      "e89d963614ad4e9caea144424057bd3d",
      "98d8ae81d9ad44bbb11742ff07b04d29",
      "4602003bfb314a8e9d16e81413c32f5b",
      "53a4e18796584b539ae060341611bed5",
      "7636710a4abd4043b281884158a5a888",
      "bd268fb9a2a540d3b0d772d591716816",
      "db5ba146b8fb435d95809a385f5602aa",
      "84c48ab5bbd14a65a9c1cacfbb807926",
      "5f1629617293498a9d32ac2c914d4b4d",
      "35ab820c334743e2ad4bc191ab21db0d",
      "534bf860ac474d658cf292c4137ad307",
      "abad5784ef0f4473849c590a0d25a885",
      "ccc31df4671849b48fe1ac318c6c13f1",
      "db4fa39f9b9b41f1b5abc41c95019de9",
      "642cc2a318b04d3d9cb0eaa06f29bf0d",
      "cfe11598ae8a4554a9d27b87ea1c794d",
      "5377d16ba3d346c99e6364dbe61f9dfc",
      "042c14c150df44d4848a8afeb6ae0530",
      "eff7100036a24d7798a96d1442f12c56",
      "0ab94171311f42f182ff5cd6d1f4ff04",
      "28906d8ba1a04ce7ba3afa457fc86018",
      "f75766daef694b56a1cc34f76ff0b203",
      "56eefbd87c1e493296380d4e5a74551e",
      "7e171fefe16d4d9e8cc85ba294088b7a",
      "ddc50960965f4835ae8c83ea729b2feb",
      "174732933634494289c92beddbd1d5d2",
      "ffa310dbd0374c15951ce7c38723e7c5",
      "020622745ff145ec927fa6bba77fbfd8",
      "ca3adb32899446a187dc0ff9fabc0abe",
      "f3aa34ec21644f0ba80f05579458b37b",
      "949501f3ff914ede9e48281f1c803d0f",
      "53f389e9aaad4f05ad5d401d926e7762",
      "fcec5033735f4d4ea6f98733f2ee5dde",
      "c4439e2e88974a448073887c9f0da77b",
      "5e9595de388b4af590725d9fcb3baa44",
      "b610e4922c804420970e8a748a2e9851",
      "e7f2b64f871346e9b25381098b8f5871",
      "9ff35217942b42b784e4f4506b5a2978",
      "9ed89d67cf924ea985b5646fc717836d",
      "32e6e568c26f40a1ba33c4bc888b8071",
      "96c6d927b5c4493ca5a397ffba43a77f",
      "9d5d13cb67ff42dd95f70faed940ec8f",
      "e8b9e35a323d445f9e5e15dad5fc6a7b",
      "bdbbfa3722ef4e7fb78a8cd7fa29cbf6",
      "2f2d253949284bdc92fe7e5fecdd341d",
      "ee43382c497044f1b409105d19b7f1b6",
      "b8911e5d80ad4999a175e65b42240ff5",
      "4ab922e817a24185885296b9b22ba479",
      "70ec0acce7904cf68de9efc51255c9ca",
      "33e5692fe9fc46be968309471de67d66",
      "c612b13aabf243448730f1a1fcb8bb0d",
      "e32ac2e2c1924e2aa6149d4d67414c7c",
      "b226d57bac6e43928f42900acc68bef7",
      "dd0200432140481083d33299606805bd",
      "87e81283800a4d549e06e5b033a602bd",
      "2e362654ff5a44388798439fb8a8992a",
      "1fff089c8b564bddb76a09ebef2c6c48",
      "48642c00f6d24ff0bbd6a11c3fb01956",
      "901d1dd4a62340a9a41cf77675c69351",
      "9a0a8e4bb3d84a20909ad7a12a1e21e1",
      "755aca40bfca45f3b2cfddf2800b39b3",
      "50731ce360d74ff2804a857418f24ae2",
      "29f0177730104d39b2a6cea12f201565",
      "8c3447e9147c42de9ecb21c76f8d4290",
      "4a0191a6519c49f4aa5e0308cb6291d8",
      "0dcbcd0ebf724bd798c2eb2f49effa4c",
      "7cc1f6568cb543309bd0da0bf177c390",
      "17cfae1d567d4fc783890c86cce853ea",
      "f99e15b31689436c8f314ffdaf86172e",
      "2a08c9bd58364f628276c9ab180b16d1",
      "d1a82d0fb74144e189fb61e35ce8f0fe",
      "3f734f38f6a64cf09b8b59a7d5e46a3a",
      "d5fbd573678b4a5287ed02b1d3b13958",
      "2096539faa314fbd8a3ddaadfd0b33a3",
      "5c6db0e0b36e407d85aa6adb9ca72986",
      "f5e7a2e177b042c2a98211001ec4ae2f",
      "8262c6bcf9bc4da3af1674d165dce2bc",
      "c471f844cb794a4aa9fc1519f0f8acf3",
      "d20c00d7af0f40aeba426fbded33f3ef",
      "99857cd3cbb44f21b8ca87dc8411d487",
      "f06549cda16e468493f977dee5788848",
      "aba442ba2aea41b79e39ab8d85ab9a7b",
      "b7b55d7a402043028cc6657885a4c159",
      "83393b0030004330ad92ac105cb1e390",
      "29c3d9d04d804daca67003f629fb7c12",
      "cc87e17f183e411baed6d8126c99d680",
      "6de4ddcf43b0472995972e0332d9c2cc",
      "b6aa177163aa435da296f9684243a8a6",
      "c7c9a2d71027450c9195f775f383ceaf",
      "a9a8abbd3ef44fd1a82aafc9421aea1b",
      "a50e198d53df4dc1ab0c44133dd4d19f",
      "329340c79fa54739b746d64b4186f184",
      "1c65a9a7eeeb46fabf6980a1d0f45ea0",
      "da46d775f16a411cb7e78a82cee5a132",
      "506f54b4ade84980bfa62d33b7fcf272",
      "604fc25595bd4b798eb80cfaa6f901a4",
      "b0ad0eb228884f138f3f81368e4490f6",
      "d00cab461bb14f72ac19af1224436f1d",
      "edf5141ccdf24322b3f9a1c17987a353",
      "ff6b615defad4021a1061639a21fb6d7",
      "0dd6427f16814a58ba108adbaa637ce6",
      "52cb2bca4cda4bf48c296085bf5cea9e",
      "54ec9cda98c44548abd3ee4772961016",
      "93dd8bebae2643ffac53da1b9af5e5a5",
      "ee785b91c6f240539796113e4d37e26e",
      "6adf756c41174e868bc0856feafaf6d4",
      "bcf789e8985d43e6a56659ce05499808",
      "4bfcfb80e02b4a6c9f7b0cfc562452e4",
      "e0780f2c98d3452a908b198dbd1de44f",
      "403f97a7e9ef4a99a459d8b0162445be",
      "0f892e5f6bb54bf7889505549cd723f6",
      "dd9558cbfc094e8fb45c96cc6f3c6568",
      "8666dcfc5f584b629ef771b1ce1c113b",
      "628d200258a246d0932fe9e3578db470",
      "22d60cf2e351431aab5d7d7d06e3b337",
      "3802edf1c9b74af792eeb3d394c4f7de",
      "bb44d556e4aa477a875127c0ef450523",
      "c5fd6c93b51a4bcda0091014448f241d",
      "aba767ad5f5d4863817175c895d7e089",
      "903a879223cd44c198efa999538d460d",
      "fec87f763bf24dc0903234b24c7e5090",
      "ada2f12571a74c8d897d46b909114d42",
      "ab88cf60fe0345af997c7fc6b7365012",
      "4d5f3509a21c48a0a283fbe9c27b9a95",
      "70a6f0732a6442ff8dcd865be9d31e38",
      "252348e0b20448babb5ec32317708f3b",
      "a7bdfc06e1764aa6a961f0bd95555fc9",
      "2c2368c0b7c640269f99f147ce5a519c",
      "a2172b3422e94d069a25245f9768d032",
      "193aecf5db7e4251b65411dead13fff7",
      "24193826690f4aeaa99e7929994fc7d9",
      "71967f2e7b004ef1be363981d10c1715",
      "e26205f726a64cd8a86157b5a31479e0",
      "f9c4cf092bb44967b9cc3da28a32dfc1",
      "16bc0182e4ba40a2a38f515a33fb50c3",
      "dcef4fea84ee4b0fb57d25ca68b84e54",
      "fff9431c9c56460088466c1eac4adfac",
      "f6ed3c730f0145219fd21c33a5e63226",
      "cc14940e27b348f3a56dde5358235c46",
      "928f3a1919064db68a6c090dcdf24f1e",
      "9a5b806be20740e393d44e152a3e9d48",
      "1d9e7fa05e174dfaae4592ddcd97a9d4",
      "c9f1217eb0f14cb2bcd2cbf1e59f06ae",
      "fd36168960904083ba8191e7a6ba2307",
      "885d902343994abf8c0a9947513f7e63",
      "c499dd30406049b6a494e0c3f8ed206d",
      "bf63076a90ba4baeb3394c55d1a23838",
      "2650f753c59145cab82bddd9d1a0284f",
      "c5daef73a92e4d44ae9252a9b6e8eeaf",
      "2230e726158340b4b004269157b97db5",
      "aac3b485fb5e4c089442cb1b614990c5",
      "8842f272b09c483ab692c67d0b948d1c",
      "669c555c105a45e982bedb393ef7e2c4",
      "5fd82dcdf9154119bb7e197676c3fa5d",
      "a5bf07cf798849a990d156f20e724ff8",
      "608be846946744d59d6568e45efb0380",
      "40c59f596d8f445ba5c272cac6f99825",
      "04f59a820f5d4541b99c412cfdcf5d0b",
      "5c8d38e3dabd4f3b9b8b3d308d8d139a",
      "c2a81661c4584bc398a947b5ab62ac5a",
      "2710ee6bd1874a43b0d9615f5cb5cfa2",
      "b480dd58ecc8424a8815cd9ec693c2fb",
      "e75e0decac7a4e0089b8ca97f52a5c08",
      "cb1671674a40471ab4390dc456cf6f65",
      "859e099088e04cc9828fc3d06b782d03",
      "71850776acca4db0bf2da31dc51bb937",
      "f621a761c8ff470c94d4b67ea742c074",
      "1d24a0d9a2654f39bd47dbfef1902347",
      "a1e6401656204d348f64d13b99091833",
      "d0539d24ec6742ef945a4d01ece27d2b",
      "65b0be3fd618409da8bfbce766d896a8",
      "af2ec9d0af50410280020927badb517c",
      "69e2e2a50fa84cd19b30e612358320fa",
      "2c9127374cc04d2fab3556471307c4cd",
      "f855d73814f34f74abd76229ac7cac61",
      "cc68fff7c19741f5becf4ebfecff8fef",
      "de466a9223bc404ea61086069d2598d5",
      "cfb08431adea47be839744dd56db1e85",
      "5dafbcb71846425b879ccbefbc0ea175",
      "dd98ead61c1643deb9887b081e5e6c2b",
      "37fbf5ba15c549e69eeab4476cb1cff1",
      "29724d1d29c848ffa9733211438be4fd",
      "aaa4f4bad74e4fa6a4c49789935bea86",
      "54fcba71b34446c8a986d325197dc202",
      "00ed9bdd70d04f1b9efa67a4b83b01cf",
      "9e501c0c947b48d5ab5ff3e20c9d192b",
      "f55669ce040f4bddbb8f02cd9ca63917",
      "e8603c77a153457bb22da2c47a575c86",
      "01e92954ba7d4f77abf405b3741e364c",
      "c3a742a0ce3c453cbe9d16903585a85a",
      "74a9b2dfb4514d40807f9ecfe7e89240",
      "7cde731fdc604ab7902f8868516a6789",
      "791f46770a7c41b9b8d6e3e1fc83f070",
      "61b9ef4697a3465895568797b9254bb1",
      "4bd79d7fd8e5403b9acd8a9a134581bc",
      "c57f03323f1a4bbc804697c3791efcbf",
      "1785c66217444bdcb8529f2eabcd9004",
      "d486315042df4282a6ffd7949e0d947c",
      "c2a5916dde304b2cbee1faa378d8aff9",
      "fa40bf65bc0c4a0d90be0d75316d55aa",
      "1158565953d246d8900bc1fe7040bafc",
      "4252984f50ab47a580d221743ecdfc00",
      "da795eecc9e14257bebbec6f7595eb8e",
      "c8616a6ea248400dad7c8e9798765f1b",
      "0354e5b14dae4d129c378cde1ca202e6",
      "0a8b702902de4b71b89b84d1adc264ff",
      "b4f40b66e09c427aa28085f5011ffe56",
      "d588a60665f64d1aadc7a3bc0bc1d91f",
      "e7a7ab4a092f447fbaf8647a990f2232",
      "49aca68d2abe4ba2ab0c72c618f174eb",
      "beb14c50b90b46f08475f621877e5a99",
      "12d3ef9398e14c8c9ecc3f6dc5df8b60",
      "7e1e5464140d49758f75d1fde53ad11f",
      "5e7c6e82126b4ab2b7cf1074f3455f47",
      "3e9fe3022a394341b5ebd7f36153973f",
      "694b43ceec63479992909761065a6fbf",
      "152005ffb73d400086f9dfe58540618c",
      "80beab51dd6f4c2a993c3bbeca906621",
      "30a80fe10cd64a1d87ff3bd3835cf226",
      "19e295e7655147329cc3d1387e6c482f",
      "54cf72e50fa84a6aafa9e6826c270b85",
      "dd8d844c491f45d6824a7e9c6c78102b",
      "c9669625bd2545659d9df63c7e555f25",
      "ff31d968f07e47f99bae64e9268cf874",
      "c698f6011c454ddd9f039d2a420c7a6f",
      "43d1555fc0c94c8284916a62da745549",
      "2afc4e9858784aa18507b61f40cdc699",
      "602f1bb3c89a49faaa93cb3ca15addf0",
      "899067c4487645e09922191f00004066",
      "ab04c84029d74a249712b07d0a71ecef",
      "a426d15c3861449c895012f5ff573103",
      "94de4fb89b3040f595c79d8947b550bf",
      "bd3e0065f18444bb9e28b6ccd72c97d7",
      "650182d06d12451980051c0ad2e6cb84",
      "99e9c92534e741f6baf94bcb5a8eacae",
      "fbec9f62cbc14137ad81d5d35f0b7460",
      "16158f361fbc492caedbd8d0997b2bb1",
      "098a853858824c5ea5ad463b4b71c433",
      "521165148e4e40d09175d886da5a080b",
      "35fbc049e0a8490eb3519d533f2ccd1f",
      "5ce587ca64f34ee79a5e4ee5d95e4693",
      "b72ddb2880774fcfbb58cd9d64919723",
      "a0f2a72b95e442509890d64e36bc1431",
      "40a8f261545e4dfdb097b4d01216f13c",
      "a502bce47cd048da8e11d9ceef934937",
      "0f9d2083ccbe44de826804446f6488c8",
      "f4cb8462e95f4a8dbd5b77af95ab2e8a",
      "8eb57579451243f69fbed3682964c9f3",
      "390d6fdb307048a3976dc1f106b86b5a",
      "bca028080cad4dde8ef7a0fe408ba1d0",
      "ef3fc9a6fd634f82884ebdddfff1c8c3",
      "d20a7800591d4f978f8fc0f06ae79120",
      "ade48c196ac24919877c60f2ebcbc7e9",
      "9ccd7bec3f6245e3b75b7783e851a643",
      "11172565849d4a258c81a7b37c445f12",
      "d4c71e4c1ffb430c84db4fe724c1b5ef",
      "bc0b2a56e0be41eca34c994a28c3dcba",
      "5366341c533143b28b0c158dac217db2",
      "83046a1b223049b19a1bc66ec9f282ec",
      "96661ee52947473d9ff5d3f4953e2b4e",
      "616a23e27c1048a0b64ecbd001331bd5",
      "395a8d73074840f8bde12b0d8af0b10f",
      "0bcef20a8dbd49ab8c9b2d877246259f",
      "992af14889bd44b5b9720df6886787f1",
      "1f19a052c3fc4f448b7076a0ec41aaa2",
      "92f829ccc4904776b4bfcce756ce4264",
      "bd2f5fe4faa3433ebe0a36483b1687b7",
      "fca9b5048d644966b7c68eaccd834822",
      "e2cb17bc604b494c9e01ad4e1634581d",
      "4257ce1b4e014398a8917fdc2a9acaad",
      "404bfe7b77c0458db77f99b0131a8f5d",
      "b362753c280b450baff38a3ce217297e",
      "847a6e30f5bb4dc3b38a4d5b2597e11e",
      "947a3b6d339a4f68b2d0816e53b7ef77",
      "2cb09d93d4674344a07d12b35bca7479",
      "a3d290b1df6f4001b387200db00d86f8",
      "5ef4382e33a04ba3ba2fe2d532ff21c7",
      "df8711a79ddc45a8b9c904c9a36eac33",
      "94455b85b0ab49e0bf89a6c68fb0ea82",
      "e015fa68468341da9377dea23b21a30c",
      "aa95185d5b1f429fa67f695d784bef95",
      "32977efa87f248f7a371a56ca4df4ba7",
      "7b85ae003b2f4b808bce0ba8c7db7c21",
      "2de9d224127145e2953dbc21b3b6e27d",
      "4d544b6d293b47838ff70398141d0909",
      "49c02c70ee424fe1a817aa64fc016bf8",
      "1d297000b9c4472dbad92bae1f0a94a0",
      "1b1a2b14bbf84ba496e8c3bf91637526",
      "cb6cfd3ead714512878f162a4c3b4698",
      "9944bff4e01d42c7a7885f23be47f219",
      "5a8e142b485f4d99bf6da4e4d338384d",
      "76d2773ce79141d69daa12124a67b1ee",
      "dd975dba552d458d95c6a08fb15c4075",
      "ac71c378ba004edb94463f59d67b2ac0",
      "3e028d2101fc4ed28c1ff15865824d44",
      "8d273ec58f5d4ea5bb892f498dad1e62",
      "4e2c9820ee704a41846deec719e487a6",
      "40aae70a0395413ca04ba682e3af8cdb",
      "270b78f8804048c5ae0ba06cdacc9269",
      "85ce286b15e54d0b8ed6367de88cb57c",
      "bdc1b497d7ae4ae99a26173018e934be",
      "18a71dcada1f4083a16d9e9d13451b60",
      "9577878d2c4046c1ad25469579f3eaa2",
      "ac5cb3544444430187db72da754ea8d9",
      "67aba68dcce8458396579e1a1ddde6dc",
      "5b6c9547f5de4a7081f4bd8952b67c0f",
      "c36a68858c0c4b79b670b50fd6c7e8cf",
      "8ea5dc6a05f5433dab2bcdecc83cc01a",
      "e8f03c90bb6744758d1394f6647f3bba",
      "111082178ec148389161530c4d58c045",
      "2a10ac3f29a54a6cb1f5f3a20df0e80a",
      "25f64e9bf9a4409f8e6b0d47a1d8dfdf",
      "50eb81a9d8e44eb9b098f8cc0241299f",
      "391573dbd4584e1f94b74a4cb889fed7",
      "e322b4b88b20401fa9c49d73da056ada",
      "30691b3dd86a44009b4462fe59cd675d",
      "fda716ed618c46dfa09b4f2ab79a9f0a",
      "285bfb7d2bf6408f99d8d3c1c8088168",
      "25a155c1e21347fc880cde23de931eeb",
      "dc3b482a4bea4dba9da832fdeff5fd36",
      "ec269e6b286a42ebae57d93d517d8cb5",
      "1172115fa1564e138164324be1ef51b8",
      "433d05bd11334807b6458e8c3b1f101a",
      "55028ad8b08f4afd84bf7212b5533731",
      "32100bd3f9d545269bf6c378cbe6042d",
      "0fa0ce73b15142e7a670eae473f5d83e",
      "5fa2ce28fa6645a88d0450822aaf9f1e",
      "50ec3b277d674f2198705d1626b352e9",
      "a6d09cec9f664b13add4d1a0b852fb2b",
      "c3a464b67b934bcc8cbaed18b42ed536",
      "9dedf1d0c44f4ee2919a7f0f38ce420f",
      "cd51ee6d5e06426f844fdead963a6152",
      "99bc446d759a412ba3494deabc368800",
      "44a3d4ae959f45c4bf6cdf43ba9256a4",
      "3c20cb62c8254fdbae826fdc5b8d58cb",
      "eb83489a28064f8db2d925192adbe01a",
      "35db4ae164f448278915d42f61d5d959",
      "86fb5cfd27e54e3f9ad05d6811c7d8f6",
      "9bc77ebdf3d946489404c22f5138acc7",
      "859ce8040b39458497885d229f790857",
      "b51d3d2eb8be4cf4b058e68ec08d6010",
      "f3bbdb79608e4387a2cf4b794b128d20",
      "a83d2515af6d462b9964ba4ace3a4ada",
      "5d1a57dbbe564fd08f15265146ea3250",
      "38fa22e3c50f4340944ad9ce280082f4",
      "83fdb73e5e0749c4876a97e0f81d4ec2",
      "aee2cbd5063145febf0d49da73ae659f",
      "a762abf0bf0b4d9d84f755faa809c511",
      "2414ecfff8904df2b872a6f4e8efc119",
      "79fe0007350d421d9f49e6ce7f288bcd",
      "e7986d2295144ff0bd6a8b87b2c9de52",
      "e3475c2e13b74cb2848fce497aff9995",
      "1aab522301e84442991d1e10e389462e",
      "60bd2865bab54035b6b71302128f7e6b",
      "e80ad73859be451ea276768dc6cddd4f",
      "21aae94750d442099f878226959e3ca1",
      "8ff4e8a14e234418adf6fb61574ac145",
      "cdf41811242f42c29a6918994083b1cd",
      "d6330cf47abf4586b79fe3ca686a8490",
      "0b1088fac4ce4da186e6c3fc23db3230",
      "58f95b31ac254b99b1421ea61bf2a6c8",
      "eb2d41b87a4b48f487775646c9287187",
      "a6d0e020755b4adba03d4a439f9e5d32",
      "b9056bc7c7394778800bcd9cf4952b81",
      "0ca8ed55cbb24322a0ca8989d38fd8eb",
      "b607102847334038857c0d8f811fa42a",
      "d7643607ebb24bffa9f7a2ea7a66cba9",
      "127d434147834054b56c9c86327254ed",
      "367095d58a3b4bc69da0fff1108bb151",
      "3ea1f96554614572b9a40ab6e3e0c7cb",
      "24ac748307e046039068bfd743c68034",
      "1f523cf08ce44db8a9b8f22c51ff33d7",
      "ab954a089f044e54b599331192654882",
      "00c51a14e3634586a42c63c1445a5287",
      "2f760b6b5b76450fad6e7ecdc6aec3f7",
      "cc9d23b9d09e4108ae2e27b65e1b8fee",
      "708ebb07592a4c3aaecd3f8fa213bd57",
      "20b95a0324f4461caa3cac2eb4fff7b8",
      "8cb7a884692c4efaa36f92e476f29de8",
      "cacef56e0481463cafc2527437fe1d19",
      "793cd02d52984e68bc88eb868dc6c840",
      "dbe3245b47a14695a468c36123b8f10c",
      "e67bbf63f1654e2a949ae7516aedd274",
      "4ed8be957956435cb6ff6015fabf6eb2",
      "64b30e65576f47838560efad89422fb1",
      "cfd7ac0da60645a2899981fd50faa46c",
      "35fd0bccbb434c898b08ed9ce0a7f4dd",
      "e1397b1aadb4467897af7eac30dcd569",
      "34a88e2f7c494e24865b29d7791e6a3a",
      "06bc1fdd642149dca8544f46afdfbe79",
      "a681de801b9b4c29ab3a86683a20295c",
      "1b4bced669784403b722a614c3f132f7",
      "4cbb5e2001314fdc9b2881134c6de1d2",
      "949181da93904edaa4e90105ee68b4ff",
      "348bdb294c6a47c38786c47e2b307b99",
      "19d1e71bf6434f0e87190c7f5e71dc57",
      "db4cc36a876b4b3ba44cce8ef4bf7ffc",
      "961f7d8d9c66416d9d34bd14d4ad737f",
      "a3db9340686d4c8997f00e59fac8a52b"
     ]
    },
    "id": "q14g_yoHCkhH",
    "outputId": "aeee9939-e2e0-463f-bf6f-9a6ea617329b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up fit stage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | In sizes          | Out sizes\n",
      "---------------------------------------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy | 0      | ?                 | ?        \n",
      "1 | train_f1  | MulticlassF1Score  | 0      | ?                 | ?        \n",
      "2 | val_acc   | MulticlassAccuracy | 0      | ?                 | ?        \n",
      "3 | val_f1    | MulticlassF1Score  | 0      | ?                 | ?        \n",
      "4 | loss      | MSELoss            | 0      | ?                 | ?        \n",
      "5 | model     | ObjectCounter      | 494 K  | [16, 3, 256, 256] | [16, 2]  \n",
      "---------------------------------------------------------------------------------\n",
      "494 K     Trainable params\n",
      "0         Non-trainable params\n",
      "494 K     Total params\n",
      "1.978     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5e8ee88951455d8d12d2e82475bb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "# Create a datamodule.\n",
    "obj_counting_dm = ObjectCounting_DM(\n",
    "                                train_val_size = 500,\n",
    "                                img_size = 256,\n",
    "                                train_val_split = (.9,.1),\n",
    "                                test_size = 100,\n",
    "                                batch_size = 16,\n",
    "                                dataloader_shuffle={\"train\": True, \"val\": True, \"test\": False},\n",
    "                                shapes_per_image = (0,3),\n",
    "                                class_probs=(1,1,0),\n",
    "                                rand_seed= 23456,\n",
    "                                class_map={\n",
    "                                    0: {\"name\": \"background\", \"gs_range\": (240, 255), \"target_color\": (0,0,0)},\n",
    "                                    1: {\"name\": \"rectangle\", \"gs_range\": (0, 50), \"target_color\": (255, 0, 0)},\n",
    "                                    2: {\"name\": \"line\", \"gs_range\": (50, 100), \"target_color\": (0, 255, 0)},\n",
    "                                    3: {\"name\": \"donut\", \"gs_range\": (100, 125), \"target_color\": (0, 0, 255)},\n",
    "                                },\n",
    "                                object_count = True,\n",
    "                                )\n",
    "\n",
    "# Create callback for ModelCheckpoints.\n",
    "checkpoint_callback = ModelCheckpoint(filename='{epoch:02d}', save_top_k = 50, monitor = \"Loss/val_loss\", every_n_epochs = 1)\n",
    "\n",
    "# Create Instance of Lightning Module.\n",
    "obj_counting_lm = LightningObjCounter(in_channels = 3,\n",
    "                                        num_classes = 2,\n",
    "                                        img_size = obj_counting_dm.img_size,\n",
    "                                        features = [8,12],\n",
    "                                        kernel_size = 3,\n",
    "                                        fc_intermediate_size = 10,\n",
    "                                        lr = 1e-6)\n",
    "\n",
    "# Define Logger.\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"object_counting\", log_graph = True)\n",
    "\n",
    "# -----------Set device.------------------\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create an instance of a Trainer.\n",
    "trainer = pl.Trainer(logger = logger, callbacks = [checkpoint_callback], accelerator = device, max_epochs = 15, log_every_n_steps = 5)\n",
    "\n",
    "# Fit.\n",
    "trainer.fit(obj_counting_lm , obj_counting_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59d46f",
   "metadata": {
    "id": "O1RLt8uCQB8I"
   },
   "source": [
    "**tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39545777",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o2_QQHdSCkhH",
    "outputId": "7db9a820-ca76-4416-f2f8-572f10ac00d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8044), started 0:18:48 ago. (Use '!kill 8044' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2c47b66b7591637a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2c47b66b7591637a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: If using firefox turn off enhanced tracking protection for the following to work.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21faa9",
   "metadata": {
    "id": "CaYm3xEaCkhH"
   },
   "source": [
    "## 9.&nbsp; Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9770f",
   "metadata": {
    "id": "VeFbAHEZF_mu"
   },
   "source": [
    "**get test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c070f39f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxIolhztCkhH",
    "outputId": "d08b7720-04cc-4c24-df3f-c41fdb4b6cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up test stage.\n"
     ]
    }
   ],
   "source": [
    "obj_counting_dm.setup(stage = \"test\")\n",
    "test_dataiter = iter(obj_counting_dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eec62",
   "metadata": {
    "id": "3Po-RrwKJd17"
   },
   "source": [
    "**execute following cell again to see more test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54e71d35",
   "metadata": {
    "id": "huXJFpNYCkhI"
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(test_dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1462a8",
   "metadata": {
    "id": "Q6hI8jmaGHxR"
   },
   "source": [
    "**visualize predictions on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9172764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909f7cef974a4f579818dd98b42202f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=14, description='epoch', max=49), Checkbox(value=False, description='dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "version = 0\n",
    "\n",
    "@interact\n",
    "def vizualize_labels_preds( epoch = widgets.IntSlider(value=14,min=0,max=49,step=1),\n",
    "                                 show_labels = widgets.Checkbox(value=False,description='display_labels'),\n",
    "                                 show_preds = widgets.Checkbox(value=True,description='display_preds'),\n",
    "                                 display_size = widgets.IntSlider(value=30,min=2,max=50,step=1),\n",
    "                        ):\n",
    "    \n",
    "    PATH = 'tb_logs/object_counting/version_{}/checkpoints/epoch={:02d}.ckpt'.format(version, epoch)\n",
    "    # Determine the device and move the model to it\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loaded_lm = LightningObjCounter.load_from_checkpoint(PATH)\n",
    "    loaded_lm.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Also move the inputs to the same device as the model \n",
    "        imgs_device = torch.stack([img.to(device) for img in imgs])\n",
    "        logits = loaded_lm(imgs_device)\n",
    "    preds = logits.round().long()\n",
    "    \n",
    "    result_images = [imgs[i] for i in range(len(imgs))]\n",
    "    \n",
    "    if  show_labels:\n",
    "        result_images = [add_labels(img, label, obj_counting_dm.class_map, object_count = True) for img, label in zip(result_images, labels)]\n",
    "    if  show_preds:\n",
    "        result_images = [add_labels(img, pred, obj_counting_dm.class_map, pred = True, object_count = True) for img, pred in zip(result_images, preds)]\n",
    "    \n",
    "    grid = make_grid(result_images)\n",
    "    show(grid, figsize = (display_size,display_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49309585",
   "metadata": {
    "id": "T-rjCGgonS7J"
   },
   "source": [
    "**visualize first conv layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5410e77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199,
     "referenced_widgets": [
      "90e031a1be154519993473a5e2145737",
      "c62c257544a5403b9ab820c44967678f",
      "d3a4af6303e34846bb864400b9c85660",
      "3509cbccce714323bc74eeae86caf4d7",
      "f110765c6afa4ebd8fea3e669d8a3c7a",
      "4e9fd0f3bc0b49c2977d963e1f6327b4",
      "f343e4f2f91b4d5aa7aba20dcea37a08",
      "2a5f02150ecb40729b3975a9aa057993",
      "b5fa9c7cdb7f48fc8b4defa014dd3225",
      "3353424c1b1743e5b45294c883665ce3"
     ]
    },
    "id": "IOIjaY-4nV7f",
    "outputId": "3ea8447c-1494-4ef5-c679-86cda661c3fd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d386bd6a015e48f2b22f7f9e313247d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=14, description='epoch', max=49), IntSlider(value=20, description='displ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "version = 0\n",
    "\n",
    "@interact\n",
    "def vizualize_labels_preds( epoch = widgets.IntSlider(value=14,min=0,max=49,step=1),\n",
    "                            display_size = widgets.IntSlider(value=20,min=2,max=50,step=1),\n",
    "                        ):\n",
    "\n",
    "    PATH = 'tb_logs/object_counting/version_{}/checkpoints/epoch={:02d}.ckpt'.format(version, epoch)\n",
    "    loaded_lm = LightningObjCounter.load_from_checkpoint(PATH)\n",
    "\n",
    "    kernels = loaded_lm.model.feature_extractor[0].conv[0].weight.data.clone()\n",
    "\n",
    "    kernel_list = [kernel/ kernel.mean() for kernel in kernels]\n",
    "\n",
    "    show(kernel_list, figsize = (display_size, display_size))\n",
    "\n",
    "    print(f\"Shape of first conv layer weights: {kernels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ed377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
