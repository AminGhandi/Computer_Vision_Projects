{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cdedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9f0e9",
   "metadata": {},
   "source": [
    "# Object detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330d3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ObjectDetection:\n",
    "    def __init__(self, weights_path=\"dnn_model/yolov4.weights\", cfg_path=\"dnn_model/yolov4.cfg\"):\n",
    "        print(\"Loading Object Detection\")\n",
    "        print(\"Running opencv dnn with YOLOv4\")\n",
    "        self.nmsThreshold = 0.4\n",
    "        self.confThreshold = 0.5\n",
    "        self.image_size = 608\n",
    "\n",
    "        # Load Network\n",
    "        net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "\n",
    "        # Enable GPU CUDA\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        self.model = cv2.dnn_DetectionModel(net)\n",
    "\n",
    "        self.classes = []\n",
    "        self.load_class_names()\n",
    "        self.colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "        self.model.setInputParams(size=(self.image_size, self.image_size), scale=1/255)\n",
    "\n",
    "    def load_class_names(self, classes_path=\"dnn_model/classes.txt\"):\n",
    "\n",
    "        with open(classes_path, \"r\") as file_object:\n",
    "            for class_name in file_object.readlines():\n",
    "                class_name = class_name.strip()\n",
    "                self.classes.append(class_name)\n",
    "\n",
    "        self.colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "        return self.classes\n",
    "\n",
    "    def detect(self, frame):\n",
    "        return self.model.detect(frame, nmsThreshold=self.nmsThreshold, confThreshold=self.confThreshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecbbc7",
   "metadata": {},
   "source": [
    "# object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86dee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_center(box):\n",
    "    x, y, w, h = box\n",
    "    center_x, center_y = int((x * 2 + w) / 2), int((y * 2 + h) / 2)\n",
    "    return center_x, center_y\n",
    "\n",
    "\n",
    "def compute_distance(point1, point2):\n",
    "    return math.hypot(point1[0] - point2[0], point1[1] - point2[1])\n",
    "\n",
    "\n",
    "def track_objects(tracked_objects, current_frame_points, track_id):\n",
    "    for object_id, prev_frame_point in list(tracked_objects.items()):\n",
    "        object_found = False\n",
    "        for this_frame_point in current_frame_points:\n",
    "            if compute_distance(prev_frame_point, this_frame_point) < 20:\n",
    "                tracked_objects[object_id] = this_frame_point\n",
    "                object_found = True\n",
    "                current_frame_points.remove(this_frame_point)\n",
    "                break\n",
    "        if not object_found:\n",
    "            del tracked_objects[object_id]\n",
    "            \n",
    "    for this_frame_point in current_frame_points:\n",
    "        tracked_objects[track_id] = this_frame_point\n",
    "        track_id += 1\n",
    "\n",
    "    return tracked_objects, track_id\n",
    "\n",
    "def is_crossing_line(point, prev_point, line_coordinates):\n",
    "    point_1, point_2 = line_coordinates\n",
    "    return ((prev_point[0] - point_1[0]) * (point_2[1] - point_1[1]) - (prev_point[1] - point_1[1]) * (point_2[0] - point_1[0])) * ((point[0] - point_1[0]) * (point_2[1] - point_1[1]) - (point[1] - point_1[1]) * (point_2[0] - point_1[0])) < 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69d7af",
   "metadata": {},
   "source": [
    "# case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3b6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Object Detection\n",
      "Running opencv dnn with YOLOv4\n"
     ]
    }
   ],
   "source": [
    "object_detector = ObjectDetection()\n",
    "video_capture = cv2.VideoCapture('los_angeles.mp4')\n",
    "\n",
    "frame_count, track_id = 0, 0\n",
    "previous_frame_points = {}\n",
    "tracked_objects = {}\n",
    "line_coordinates = [(100, 580), (1520, 580)]\n",
    "crossed_count = 0\n",
    "trajectories = {}\n",
    "\n",
    "while True:\n",
    "    frame_count += 1\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    class_ids, scores, boxes = object_detector.detect(frame)\n",
    "    current_frame_points = [compute_center(box) for box in boxes]\n",
    "    \n",
    "    for box in boxes:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    if frame_count <= 2:\n",
    "        tracked_objects, track_id = track_objects(tracked_objects, current_frame_points, track_id)\n",
    "    else:\n",
    "        tracked_objects, track_id = track_objects(tracked_objects, current_frame_points, track_id)\n",
    "\n",
    "    # Check if the objects have crossed the line\n",
    "    for obj_id, point in tracked_objects.items():\n",
    "        prev_point = previous_frame_points.get(obj_id)\n",
    "        if prev_point and is_crossing_line(point, prev_point, line_coordinates):\n",
    "            crossed_count += 1\n",
    "            \n",
    "        if obj_id not in trajectories:\n",
    "            trajectories[obj_id] = [point]\n",
    "        else:\n",
    "            trajectories[obj_id].append(point)    \n",
    "            \n",
    "        # Draw trajectory of each object\n",
    "        for point_idx in range(1, len(trajectories[obj_id])):\n",
    "            cv2.line(frame, trajectories[obj_id][point_idx - 1], trajectories[obj_id][point_idx], (0, 0, 255), 1)\n",
    "            \n",
    "        cv2.circle(frame, point, 5, (0, 0, 255), -1)\n",
    "        cv2.putText(frame, str(obj_id), point, 0, 0.5, (0, 0, 255), 1)\n",
    "        \n",
    "    previous_frame_points = {k: v for k, v in tracked_objects.items()}\n",
    "\n",
    "   # Draw the stationary line on the frame\n",
    "    cv2.line(frame, *line_coordinates, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Crossed count: {crossed_count}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3776e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
